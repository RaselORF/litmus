---
## Test involved.
#Check if the application is running already.
#Selct one of the replicas.
#Introduce packet drop in the selected replica.
#Create snapshot.
#check if the snapshot is not present in the degraded pod.
#Bring up the replica.
#Check if the snapshot is rebuilt.

- hosts: localhost
  connection: local

  vars_files:
    - test_vars.yml

  tasks:
    - block:

      ## Generating the testname.
        - include_tasks: /common/utils/create_testname.yml

         ## RECORD START-OF-TEST IN LITMUS RESULT CR
        - include_tasks: "/common/utils/update_litmus_result_resource.yml"
          vars:
            status: 'SOT'

        - name: Generate unique string for use in dbname
          shell: echo $(mktemp) | cut -d '.' -f 2
          args:
            executable: /bin/bash
          register: snap_name

         ## Check if the application is running.
        - name: Checking if the application is up and running.
          shell: kubectl get pods -n {{ namespace }} -l {{ application_label }} --no-headers -o custom-columns=:status.phase
          args:
            executable: /bin/bash
          register: app_status
          until: "'Running' in app_status.stdout"
          delay: 10
          retries: 3

        - name: Derive PV name from PVC
          shell: >
            kubectl get pvc {{ app_pvc }} -n {{ namespace }}
            --no-headers -o custom-columns=:spec.volumeName
          args:
            executable: /bin/bash
          register: pv

        - name: Derive the cstor target using pv.
          shell: >
            kubectl get pods -n {{ operator_ns }} -l openebs.io/persistent-volume={{ pv.stdout }} 
            -l openebs.io/target=cstor-target -o custom-columns=:metadata.name --no-headers
          args:
            executable: /bin/bash
          register: cstor_target

        - name: Obtaining the consistency factor of cstor target.
          shell: >
            kubectl exec -it {{ cstor_target.stdout }} -n {{ operator_ns }} --container cstor-istgt 
            -- cat /usr/local/etc/istgt/istgt.conf | grep -A8 "{{ pv.stdout }}" | grep ConsistencyFactor| cut -d ' ' -f 4
          args:
            executable: /bin/bash
          register: consistency_factor

       - name: Create an empty list of replica pods.
          set_fact:
            cstor_replicas_pod : []

        - name: Obtaining the pool deployments from cvr
          shell: >
            kubectl get cvr -n {{ operator_ns }}
            -l openebs.io/persistent-volume={{ pv.stdout }} --no-headers
            -o=jsonpath='{range .items[*]}{.metadata.labels.cstorpool\.openebs\.io\/name}{"\n"}{end}'
          args:
            executable: /bin/bash
          register: pool_deployment

        - name: Find the replication factor by getting count of pool deployment Create an empty list of replica pods.
          set_fact:
            replication_factor: {{ pool_deployment.stdout_lines | length }}

        - name: Obtaining the replicasets corresponding to pool deployements.
          shell: >
            kubectl get rs --selector=app=cstor-pool -n {{ operator_ns }} --no-headers
            -o=jsonpath='{.items[?(@.metadata.ownerReferences[0].name=="{{item}}")].metadata.name}'
          register: rs_list
          with_items:
            - "{{ pool_deployment.stdout_lines }}"

        - name: Obtaining the pool pods
          shell: >
            kubectl get pod --selector=app=cstor-pool -n {{ operator_ns }} --no-headers
            -o=jsonpath='{.items[?(@.metadata.ownerReferences[0].name=="{{item.stdout}}")].metadata.name}'
          register: pool_pods
          with_items:
            - "{{ rs_list.results }}"

        - name: Build a list of replica pods.
          set_fact:
            cstor_replicas_pod : "{{ cstor_replicas_pod }} + [ '{{ item.stdout }}' ]"
          with_items: "{{ pool_pods.results }}"

        # #Select any cstor replica pod to inject packet loss
        - set_fact:
            replica_pod: "{{ cstor_replicas_pod | list | first }}"

        - name: Making sure number of healthy pods is equal to replication factor
          shell: >
            kubectl exec -it {{ cstor_target.stdout }} -n {{ operator_ns }} --container  cstor-istgt 
            -- istgtcontrol -q replica |json_pp | jq '.volumeStatus[0].replicaStatus[].status' | grep Healthy | wc -l
          args:
            executable: /bin/bash
          register: healthy_pods
          until: "healthy_pods.stdout == replication_factor"
          delay: 15
          retries: 30
 
        ## Inducing the packet drop on the above pool pod.
        - include_tasks: "/chaoslib/openebs/inject_packet_loss_tc.yml"
          vars:
            status: "induce"
            target_pod: "{{ replica_pod }}"
            operator_namespace: "{{ operator_ns }}"

        - name: Check if the targeted replica is disconnected.
          shell: >
            kubectl exec -it {{ cstor_target.stdout }} -n {{ operator_ns }} --container  cstor-istgt 
            -- istgtcontrol -q replica |json_pp | jq '.volumeStatus[0].replicaStatus[].status' | grep Healthy | wc -l
          register: connected_replica
          until: "connected_replica.stdout == (healthy_pods.stdout | int - 1)"
          delay: 15
          retries: 30
        
        - name: Creating snapshot.
          include_tasks: /funclib/kubectl/k8s_snapshot_clone/create_snapshot.yml 
          vars:
            app_ns: "{{ namespace }}"
            snapshot_name: "{{ snap_name }}"
            pvc_name: "{{ app_pvc }}"

        - name: Checking if the snapshot is not created in the degraded replica.
          shell: kubectl exec -ti {{ replica_pod }} -n {{ operator_ns }} --container cstor-pool -- zfs list -t snapshot
          args:
            executable: /bin/bash
          register: list_snap
          failed_when: "snap_name in list_snap.stdout"

        ## Removing the packet drop rule by including the relevant util..
        - include_tasks: "/chaoslib/openebs/inject_packet_loss_tc.yml"
          vars:
            status: "remove"
            target_pod: "{{ replica_pod }}"
            operator_namespace: "{{ operator_ns }}"

        - name: Form the snap name being rebuilt.
          set_fact:
            name: "{{ pv.stdout }}@rebuild_snap"

        - name: Check if the snapshot is being rebuilt.
          shell: kubectl exec -it {{ replica_pod }} -n {{ operator_ns }} --container cstor-pool -- zfs list -t snapshot
          args:
            executable: /bin/bash
          register: list_snap
          until: "name in list_snap.stdout"
          delay: 30
          retries: 20
 
        - debug:
            msg: "Snapshot is being rebuilt"

        - name: Check if the snapshot rebuild is successful.
          shell: >
            kubectl exec -ti {{ replica_pod }} -n {{ operator_ns }} -c cstor-pool 
            -- zfs stats |json_pp| grep "rebuildStatus" |awk -F ':' '{print $2}' | tr -d '"' | tr -d ','
          args:
            executable: /bin/bash
          register: snap_result
          until: "'DONE' in snap_result.stdout"
          delay: 20
          retries: 100

        - name: Check if the snapshot is rebuilt.
          shell: kubectl exec -it {{ replica_pod }} -n {{ operator_ns }} --container cstor-pool -- zfs list -t snapshot
          args:
            executable: /bin/bash
          register: list_snap
          failed_when: "snap_name not in list_snap.stdout"

        - set_fact:
            flag: "Pass"

      rescue:
        - set_fact:
            flag: "Fail"

      always:
            ## RECORD END-OF-TEST IN LITMUS RESULT CR
        - include_tasks: /common/utils/update_litmus_result_resource.yml
          vars:
            status: 'EOT'
